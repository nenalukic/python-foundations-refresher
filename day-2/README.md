# Day 2 â€“ Working with Files, Data, and the OS

## ðŸ“š Overview

On Day 2, we are focusing on **reading, writing, and managing data files** â€” one of the most common tasks for a Data Engineer.
We will explore how Python handles **text**, **CSV**, and **JSON** files, and how to automate file operations using **os** and **pathlib** modules.

---

## ðŸ§  Key Concepts

### 1. File I/O Basics

Read and write text files safely using `with open()` context managers.

ðŸ’¡ Always use `with open(...)` â€” it automatically closes files and prevents data loss.

---

### 2. Working with CSV Files

CSV files store tabular data.
We used Pythonâ€™s built-in `csv` module for reading and writing.

---

### 3. Working with JSON Files

JSON is used for structured data (e.g., API responses, config files).

ðŸ§© Difference between `json.dump()` and `json.dumps()`:

* `dump()` â†’ writes to a **file**
* `dumps()` â†’ returns a **string**

---

### 4. Working with the OS and File System

Use `os` and `pathlib` to automate directory operations.

---

### 5. Mini Project â€“ Combine Multiple CSV Files

Combine all CSVs in a folder into a single dataset.

---

## âœ… Takeaways

1. Use `with open()` for safe file handling.
2. Understand when to use `csv` vs `json` for structured data.
3. Automate folder and file operations using `os` and `pathlib`.
4. Combine, clean, and transform multiple files programmatically.

